I"6<h1 id="分类模型评价方法">分类模型评价方法</h1>

<p>评估分类器（分类模型）相对于评估回归器通常要复杂，本篇以MNIST数据集的手写数字识别分类为例，记录常用的分类器评估方法。</p>

<h2 id="交叉验证cross-validation">交叉验证：Cross-Validation</h2>

<ol>
  <li>
    <p>留一交叉验证：（Leave-One-Out Cross Validation记为LOO-CV）<strong>在数据缺乏的情况下使用</strong>，如果设原始数据有N个样本，那么LOO-CV就是N-CV，即每个样本单独作为验证集，其余的N-1个样本作为训练集，故LOO-CV会得到N个模型，用这N个模型最终的验证集的分类准确率的平均数作为此下LOO-CV分类器的性能指标。</p>
  </li>
  <li>
    <p>k折交叉验证：将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型，用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标。K一般大于等于2，实际操作时一般从3开始取，只有在原始数据集合数据量小的时候才会尝试取2。</p>
  </li>
</ol>

<p><img src="https://img-blog.csdn.net/20180605113101667?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MDQ3NTQ1MA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#K折交叉验证
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="n">scores</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">X_pca_3</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>  
<span class="k">print</span><span class="p">(</span><span class="s">"5折交叉验证平均准确率："</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</code></pre></div></div>

<p>交叉验证的局限在于面对样本分布极不均匀的情况下，例如分类正例反例时，样本中正例数目极多，那么分类正例的成功概率自然会很高，如此得到交叉验证的高准确性可信度较低。</p>

<h2 id="混淆矩阵confusion-matrix">混淆矩阵：Confusion Matrix</h2>
<p>考虑最简单的二分类情况，分类出错的可能有FP（假正例，原本是反例，误分类为正例），FN（假反例，原本是正例，误分类为反例）。
<img src="https://img-blog.csdnimg.cn/6d14071004264f7d8bd1656c09977a39.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span><span class="n">name</span><span class="p">):</span>
    <span class="n">y_pre</span><span class="o">=</span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">confusion</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pre</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
    <span class="n">classes</span><span class="p">.</span><span class="n">sort</span><span class="p">()</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">confusion</span><span class="p">))</span>
    <span class="n">iters</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">([[[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">],(</span><span class="n">confusion</span><span class="p">.</span><span class="n">size</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">iters</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">confusion</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>   <span class="c1">#显示对应的数字
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Confusion matrix of %s "</span><span class="o">%</span><span class="n">name</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
    <span class="c1"># plt.ylim(len(confusion)-0.5,-0.5)
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'prediction'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'reality'</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span><span class="s">'LogistRegression'</span><span class="p">)</span><span class="err">`</span>
</code></pre></div></div>
<p><img src="https://img-blog.csdnimg.cn/776706a8c1e743e088b31cc1ce117aa6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" />混淆矩阵沿着主对角线的分布集中度越高，代表模型的分类精度越高。</p>

<h2 id="精确率召回率查准率查全率precision-and-recall">精确率&amp;召回率（查准率&amp;查全率）：Precision and Recall</h2>

\[P = TP/(TP+FP)\]

<p>精确率针对预测结果而言，又称查准率，即预测结果中预测正确的正样本所占总预测次数的比率，该值越大证明预测结果的准确率越高
\(R = TP/(TP+FN)\)
召回率针对原有样本而言，又成查全率，即预测模型预测正确的正样本占总的真实样本的比率，该值越大证明预测结果中预测到的正例数相对于样本中实际的正例数越全。所谓召回，可理解为真实的正例数在预测中再次预测出，即被召回。</p>

<p><img src="https://img-blog.csdnimg.cn/6d14071004264f7d8bd1656c09977a39.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" /></p>
<ul>
  <li>精确率/召回率权衡 ：Precision/Recall Tradeoff
精确率与召回率通常无法同时取得比较理想的结果，考虑实际中模型5分类器预测的过程，模型通过训练最终得到一个判断的阈值threshold，高于threshold判断为5，反之为非5，显而易见的时，当高阈值的情况下精确性更高，而低阈值的情况下召回率更高，即分类模型可囊括的真实正实例5的数目越多。
<img src="https://img-blog.csdnimg.cn/29d7982c2b8b4d3f9e5d7efc10fd64d1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" /></li>
</ul>

<p><img src="https://img-blog.csdnimg.cn/515eddacff7547eab9125db1c68356bc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="" />
高精确率和高召回率的取舍通常取决于我们需要解决的实际问题，例如我们要训练一个视频分类器，以避免将不好的内容推送给用户时，假如这里的5代表健康的视频，那么我们倾向于模型具有更高的准确性，以保证推送给用户的视频尽可能的健康，尽管这样可能会导致召回率的下降，即将一些原本健康的视频分到问题视频的类别中；在另一种情况下，考虑机场视频监控中可疑扒手识别模型中，假如这里的5代表偷窃行为，那么我们更倾向于模型能够具有更高的召回率，以尽可能地不放过任何一个扒手，尽管这样做可能会导致模型准确性下降，以至于错误警报增多。
	准确率与召回率的权衡也可能通过绘制以准确率和召回率为坐标轴的图像曲线来看，通常称为PR曲线：
	<img src="https://img-blog.csdnimg.cn/ec836e78d3a446308185170f45f89b5c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" />
通过该图，结合自己的实际情况，可以在确保精确率或者召回率一方达到要求的同时，仅可能选择另一参数更高的阈值，来得到符合期望的模型效果。</p>

<p>此外，当模型的准确率和召回率相近时，可以使用准确率和召回率的调和平均数，通常称为F1得分，来评价模型分数
   \begin{equation}
   F_{1}=\frac{2}{\frac{1}{\text { precision }}+\frac{1}{\text { recall }}}=2 \times \frac{\text { precision } \times \text { recall }}{\text { precision }+\text { recall }}=\frac{T P}{T P+\frac{F N+F P}{2}}
   \end{equation}</p>

<h2 id="受试者工作特征曲线receiver--operating--characteristic--roc--curve">受试者工作特征曲线：receiver  operating  characteristic  (ROC)  curve</h2>

<p>得此名的原因在于曲线上各点反映着相同的感受性，它们都是对同一信号刺激的反应，只不过是在几种不同的判定标准下所得的结果而已。
它与精确率/召回率曲线非常相似，但 ROC 曲线不是绘制精确率与召回率的关系图，而是绘制真阳性率（召回的另一个名称）与假阳性率的关系图。所谓真阳性率即为召回率，而假阳性率(false positive rate)，即真实为阴性的被误认为是阳性的样本占原有样本的比率，它等价于1-真阴性率，真阴性率即真实为阴性且预测为阴性所在预测样本中的比率，真阴性率可以称为以阴性为主的准确率。</p>

<p>\(TPR = TP/(TP+FN)\)
\(FPR = FP/(FP+TN) = 1-TNR\)
\(TNR = TN/(TN+FP)\)
<img src="https://img-blog.csdnimg.cn/e96a073c5ed2414f96ba09e78cf9445a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Iq45YWu,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" />
FPR和TPR曲线同样具有类似准确率和召回率那样的权衡，上图虚线代表随机分类器的结果，一个好的分类器会尽可能的远离该虚线。
一种比较分类器好坏的方法是比较ROC曲线下方的面积（Area Under the Curve），面积接近为1的分类器是最为理想的。
	ROC曲线和PR曲线是十分类似的，经验法则告诉我们，当样本中阳性例数目较少，或者我们更加关心假阳性（假阳性为小概率）时，选择PR曲线，反之选择ROC曲线。</p>
:ET